import google.cloud.bigquery as bigquery
import google.cloud.storage as storage

def process_file(event, context):
    # Nombre del archivo subido
    file_name = event['name']
    bucket_name = event['bucket']

    # Verifica que el archivo se ha subido al bucket correcto
    if bucket_name != 'upload_archive':
        print(f"Archivo subido en un bucket no deseado: {bucket_name}")
        return
    
    # Inicializa el cliente de BigQuery
    client = bigquery.Client()

    # Ejecuta las consultas en BigQuery
    queries = [
        """
        -- Crear una tabla externa con archivos en el bucket
        CREATE OR REPLACE EXTERNAL TABLE `proyectocarbonia.alcance2.object_table`
        WITH CONNECTION `proyectocarbonia.us.con_1`
        OPTIONS(
          object_metadata = 'SIMPLE',
          uris = ['gs://upload_archive/*']
        );
        """,
        """
        -- Crear la tabla parseada con Document AI
        CREATE OR REPLACE TABLE `proyectocarbonia.alcance2.parse_table`
        AS
        SELECT *
        FROM ML.PROCESS_DOCUMENT(
          MODEL `proyectocarbonia.alcance2.con_1`,
          TABLE `proyectocarbonia.alcance2.object_table`
        );
        """,
        """
        -- Insertar los datos procesados en la tabla final
        INSERT INTO `proyectocarbonia.alcance2.silver_parse_table` (
            id, 
            nom_dist, 
            num_bol, 
            nom_cli, 
            num_cli, 
            fec_ini, 
            fec_ter,
            consumo
        )
        SELECT
            CONCAT(REPLACE(num_bol, '.', ''), '-', num_cli) AS id, 
            nom_dist, 
            SAFE_CAST(REPLACE(num_bol, '.', '') AS INT64) AS num_bol, 
            nom_cli, 
            num_cli,
            CASE 
                WHEN REGEXP_CONTAINS(fec_ini, r'[0-9]{2} [a-z]{3} [0-9]{4}') THEN 
                    PARSE_DATE('%d %b %Y',
                        REPLACE(
                            REPLACE(fec_ini, 'ene', 'jan'),
                            'feb', 'feb')
                    )
                WHEN REGEXP_CONTAINS(fec_ini, r'[0-9]{1,2}/[0-9]{2}/[0-9]{4}') THEN 
                    PARSE_DATE('%d/%m/%Y', fec_ini)
                ELSE NULL
            END AS fec_ini,
            CASE 
                WHEN REGEXP_CONTAINS(fec_ter, r'[0-9]{2} [a-z]{3} [0-9]{4}') THEN 
                    PARSE_DATE('%d %b %Y',
                        REPLACE(
                            REPLACE(fec_ter, 'ene', 'jan'),
                            'feb', 'feb')
                    )
                ELSE NULL
            END AS fec_ter,
            IFNULL(SAFE_CAST(REPLACE(consumo, '.', '') AS FLOAT64), 0) AS consumo
        FROM `proyectocarbonia.alcance2.parse_table`;
        """,
        """
        -- Actualizar los valores de CO2 y TCO2
        UPDATE `proyectocarbonia.alcance2.silver_parse_table`
        SET CO2 = consumo * 242,
            TCO2 = (
                IFNULL(CO2, 0) + 
                IFNULL(NO2, 0) + 
                IFNULL(CH4, 0)
            ) / 1000000
        WHERE consumo IS NOT NULL;
        """
    ]

    # Ejecuta cada query secuencialmente con manejo de errores
    for query in queries:
        try:
            client.query(query).result()
            print(f"Query ejecutada exitosamente: {query[:50]}...")  # Muestra parte de la consulta para identificarla
        except Exception as e:
            print(f"Error ejecutando la query: {str(e)}")
    
    print(f"Archivo {file_name} procesado correctamente.")
